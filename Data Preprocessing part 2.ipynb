{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of preprocessing, we tokenize our sentences and get rid of any data that are not necessary for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pickle\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def open_pickle(data):\n",
    "    pickle_in = open(data, 'rb')\n",
    "    return pickle.load(pickle_in)\n",
    "\n",
    "def write_to_pickle(data, file_name):\n",
    "    pickle_out = open(file_name, 'wb')\n",
    "    pickle.dump(data, pickle_out)\n",
    "    pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = open_pickle('./train_data_preprocessed.pickle')\n",
    "test_data = open_pickle('./test_data_preprocessed.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps to perform\n",
    "\n",
    "1. Change NaNs in 'ddi_type' column to none\n",
    "2. Remove negative instances\n",
    "3. Tokenize sentences\n",
    "4. Remove unecessary columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10178"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data[train_data['removal_flag'] == 1]['ddi_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "effect       1690\n",
       "mechanism    1325\n",
       "advise        826\n",
       "int           188\n",
       "Name: ddi_type, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['ddi_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "advise       250\n",
       "effect       114\n",
       "mechanism     89\n",
       "int            7\n",
       "Name: ddi_type, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[train_data['removal_flag'] == 1]['ddi_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "effect       1576\n",
       "mechanism    1236\n",
       "advise        576\n",
       "int           181\n",
       "Name: ddi_type, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[train_data['removal_flag'] == 0]['ddi_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "advise       250\n",
       "effect       108\n",
       "mechanism     85\n",
       "int            6\n",
       "Name: ddi_type, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[train_data['negative'] == 1]['ddi_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "effect       3\n",
       "mechanism    1\n",
       "advise       1\n",
       "int          1\n",
       "Name: ddi_type, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[train_data['in_series'] == 1]['ddi_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fairly large proportion of the positive drug-drug interaction examples are removed due to the presence of negation words. To reduce this, we can remove more specific negation phrases are are more likely to be present in negative drug-drug interaction statements as found in our previous exploratory data analysis. These include:\n",
    "* 'no effect'\n",
    "* 'not affect'\n",
    "* 'no significant'\n",
    "* 'no clinically'\n",
    "* 'not significantly'\n",
    "* 'not alter'\n",
    "* 'no affected'\n",
    "* 'not have'\n",
    "* 'not altered'\n",
    "* 'not influence'\n",
    "* 'not result'\n",
    "* 'no pharmacokinetic'\n",
    "* 'no evidence'\n",
    "* 'not a'\n",
    "* 'no formal'\n",
    "* 'not appear'\n",
    "* 'not apparent'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def identify_negatives(row):\n",
    "    '''returns 1 if there is a presence of a negative phrase, 0 otherwise'''\n",
    "    pattern = re.compile(\"no effect|not affect|no significant|no clinically|not significantly|not alter|no affected|not have|not altered|not influence|not result|no pharmacokinetic|no evidence|not a|no formal|not appear|not apparent|not significant|not been|not known\")\n",
    "    match = re.search(pattern, row['text'].lower())\n",
    "    if match:\n",
    "        return 1\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data['negative_phrase'] = train_data.apply(identify_negatives, axis = 1)\n",
    "test_data['negative_phrase'] = test_data.apply(identify_negatives, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mechanism    44\n",
       "advise       43\n",
       "effect       31\n",
       "int           2\n",
       "Name: ddi_type, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[train_data['negative_phrase'] == 1]['ddi_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2830"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(train_data['negative_phrase'] == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By limiting the negative instance removal to certain negation phrases, we filter out less of the positive DDIs while keeping the number of negative DDIs filtered out relatively high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data['removal_flag_2'] = train_data.apply(lambda x: max(x['same_drug'], x['negative_phrase'], x['in_series'], x['special_cases']), axis = 1)\n",
    "test_data['removal_flag_2'] = test_data.apply(lambda x: max(x['same_drug'], x['negative_phrase'], x['in_series'], x['special_cases']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mechanism    49\n",
       "advise       45\n",
       "effect       37\n",
       "int           3\n",
       "Name: ddi_type, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[train_data['removal_flag_2'] == 1]['ddi_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing flagged negative instances inadvertently tags some drug-drug interactions as false negatives and we will lose these examples in the training set; however, considering that there are about 8,600 instances that are removed, the proportion of false negatives is small and we are willing to make this trade off to have a stronger model at trainig."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(data, train = True):\n",
    "    d = deepcopy(data)\n",
    "    d['ddi_type'] = d['ddi_type'].fillna('none')\n",
    "    output_columns = ['text','tokenized_sentences', 'drug1', 'drug2', 'ddi', 'ddi_type']\n",
    "    if train:\n",
    "        d = d[d['removal_flag_2'] == 0]\n",
    "    \n",
    "    d['tokenized_sentences'] = d.apply(lambda row: \" \".join(nltk.word_tokenize(row['anonymized_text'])), axis = 1)\n",
    "    \n",
    "    if not train:\n",
    "        d_pos = d[d['removal_flag_2'] == 0]\n",
    "        d_neg = d[d['removal_flag_2'] == 1]\n",
    "        return (d_pos[output_columns], d_neg[output_columns])\n",
    "    return d[output_columns]\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_final = preprocess(train_data, train = True)\n",
    "test_data_final, test_data_negatives = preprocess(test_data, train = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19204"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3894"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1832"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data_negatives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since tokenized sentences are easier to parse with regular expressions, we pass through the tokenized sentences to remove any other drug pair mentions in the same series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def series_2(row):\n",
    "    patterns = [re.compile(\"drug1 [;,] ([a-zA-Z0-9*]* [;,])+ drug2\"), \n",
    "                re.compile(\"drug1 [;,] (([a-zA-Z0-9*]* ){1,4}[;,])+ drug2\")]\n",
    "    for pattern in patterns:\n",
    "        if re.search(pattern, row['tokenized_sentences']):\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def preprocess_second_pass(data, train = True):\n",
    "    output_columns = ['text','tokenized_sentences', 'drug1', 'drug2', 'ddi', 'ddi_type']\n",
    "    data['series_flag'] = data.apply(lambda row: series_2(row), axis = 1)\n",
    "    if train:\n",
    "        return data[data['series_flag'] == 0][output_columns]\n",
    "    else:\n",
    "        negs = data[data['series_flag'] == 1][output_columns]\n",
    "        pos = data[data['series_flag'] == 0][output_columns]\n",
    "        return (pos, negs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_final_2 = preprocess_second_pass(train_data_final, train = True)\n",
    "test_data_final_2, test_data_negatives_2 = preprocess_second_pass(test_data_final, train = False)\n",
    "test_negatives = test_data_negatives.append(test_data_negatives_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_negatives = test_negatives.reset_index(drop = True)\n",
    "train = train_data_final_2.reset_index(drop = True)\n",
    "test = test_data_final_2.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counts_after = train['ddi_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counts_before = train_data['ddi_type'].value_counts()\n",
    "counts_before = counts_before.append(pd.Series([len(train_data) - sum(counts_before)]))\n",
    "counts_before.index = ['effect', 'mechanism', 'advise', 'int', 'none']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "effect        1690\n",
       "mechanism     1325\n",
       "advise         826\n",
       "int            188\n",
       "none         23846\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "none         14155\n",
       "effect        1653\n",
       "mechanism     1276\n",
       "advise         781\n",
       "int            185\n",
       "Name: ddi_type, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "advise         45\n",
       "effect         37\n",
       "int             3\n",
       "mechanism      49\n",
       "none         9691\n",
       "dtype: int64"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_before - counts_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "advise       0.945521\n",
       "effect       0.978107\n",
       "int          0.984043\n",
       "mechanism    0.963019\n",
       "none         0.593601\n",
       "dtype: float64"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_after/counts_before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After negative instance filtering, we filter out 9691 examples of 'none' while keeping the false negative rate at a minimum. We managed to preserve about 95% of the DDI examples while filtering out about 40% of the 'none' examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_to_pickle(train, 'train_complete_processed.pickle')\n",
    "write_to_pickle(test, 'test_complete_processed.pickle')\n",
    "write_to_pickle(test_negatives, 'test_negatives_processed.pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
